{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDbJWoO1yO8e"
   },
   "source": [
    "# Image Classification with CNN - LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzQxqD6HyO8i"
   },
   "source": [
    "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFyVotRvyO8j"
   },
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTHLyL1fyO8j",
    "outputId": "19e29ee8-1f18-447b-a6b2-9ae79effb408",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# # # If your computer is slow, try to use a subset of data, e.g.\n",
    "# X_train = X_train[:10000]\n",
    "# y_train = y_train[:10000]\n",
    "# X_test = X_test[:2000]\n",
    "# y_test = y_test[:2000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ShXIANyO8l"
   },
   "source": [
    "As you already know, this dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BvNG0PbyO8l"
   },
   "source": [
    "You can have a look at some images if needed, even if you already know them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "lnjqgv-GyO8m",
    "outputId": "3666f0d8-de2c-4709-b746-b1cf0c459f53",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "plt.imshow(X_train[idx], cmap='gray_r')\n",
    "plt.title(label_class[y_train[idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdYH6XW1yO8n"
   },
   "source": [
    "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fjv8XMPByO8o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make the data preparation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "X_train_norm = X_train / 255.0\n",
    "X_test_norm = X_test / 255.0\n",
    "\n",
    "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
    "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train_norm.shape #Should be (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9LKzxR9yO8o"
   },
   "source": [
    "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
    "\n",
    "The architecture is the following:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GKyMFlL6yO8o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\61406\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ C1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ S2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ C3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ S4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ C5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ F6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ C1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │            \u001b[38;5;34m60\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ S2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ C3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ S4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ C5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m48,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ F6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │        \u001b[38;5;34m10,164\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Build your model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def lenet5():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(units=120, activation='relu', name='C5'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(units=84, activation='relu', name='F6'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'softmax', name='Output'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "lenet5().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1qBEauqyO8p"
   },
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPL3aKnyyO8p",
    "outputId": "9157f4ba-7840-4080-ecf9-7826ebca3f94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.3661 - loss: 2.0373 - val_accuracy: 0.6585 - val_loss: 0.9706\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6949 - loss: 0.8455 - val_accuracy: 0.7441 - val_loss: 0.6765\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7581 - loss: 0.6386 - val_accuracy: 0.7680 - val_loss: 0.6014\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7853 - loss: 0.5692 - val_accuracy: 0.7945 - val_loss: 0.5562\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8041 - loss: 0.5267 - val_accuracy: 0.8089 - val_loss: 0.5200\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8202 - loss: 0.4957 - val_accuracy: 0.8197 - val_loss: 0.4911\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8313 - loss: 0.4706 - val_accuracy: 0.8221 - val_loss: 0.4786\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8399 - loss: 0.4448 - val_accuracy: 0.8228 - val_loss: 0.4816\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8397 - loss: 0.4407 - val_accuracy: 0.8333 - val_loss: 0.4564\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8456 - loss: 0.4284 - val_accuracy: 0.8418 - val_loss: 0.4382\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8521 - loss: 0.4158 - val_accuracy: 0.8426 - val_loss: 0.4359\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8514 - loss: 0.4080 - val_accuracy: 0.8471 - val_loss: 0.4249\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8598 - loss: 0.3949 - val_accuracy: 0.8507 - val_loss: 0.4142\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8589 - loss: 0.3926 - val_accuracy: 0.8462 - val_loss: 0.4230\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8598 - loss: 0.3894 - val_accuracy: 0.8505 - val_loss: 0.4153\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8659 - loss: 0.3751 - val_accuracy: 0.8547 - val_loss: 0.4015\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8654 - loss: 0.3728 - val_accuracy: 0.8581 - val_loss: 0.3931\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8688 - loss: 0.3656 - val_accuracy: 0.8561 - val_loss: 0.3979\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8683 - loss: 0.3639 - val_accuracy: 0.8620 - val_loss: 0.3851\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8737 - loss: 0.3561 - val_accuracy: 0.8611 - val_loss: 0.3840\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8712 - loss: 0.3581 - val_accuracy: 0.8579 - val_loss: 0.3906\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8724 - loss: 0.3535 - val_accuracy: 0.8650 - val_loss: 0.3772\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8722 - loss: 0.3486 - val_accuracy: 0.8651 - val_loss: 0.3747\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8768 - loss: 0.3427 - val_accuracy: 0.8684 - val_loss: 0.3676\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8770 - loss: 0.3371 - val_accuracy: 0.8658 - val_loss: 0.3742\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8770 - loss: 0.3346 - val_accuracy: 0.8695 - val_loss: 0.3639\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8784 - loss: 0.3324 - val_accuracy: 0.8688 - val_loss: 0.3628\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8830 - loss: 0.3228 - val_accuracy: 0.8732 - val_loss: 0.3548\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8818 - loss: 0.3253 - val_accuracy: 0.8708 - val_loss: 0.3609\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8813 - loss: 0.3251 - val_accuracy: 0.8690 - val_loss: 0.3637\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8826 - loss: 0.3221 - val_accuracy: 0.8739 - val_loss: 0.3495\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8806 - loss: 0.3279 - val_accuracy: 0.8734 - val_loss: 0.3506\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8850 - loss: 0.3119 - val_accuracy: 0.8747 - val_loss: 0.3472\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8845 - loss: 0.3126 - val_accuracy: 0.8752 - val_loss: 0.3485\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8847 - loss: 0.3135 - val_accuracy: 0.8729 - val_loss: 0.3497\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8871 - loss: 0.3087 - val_accuracy: 0.8743 - val_loss: 0.3453\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8845 - loss: 0.3092 - val_accuracy: 0.8731 - val_loss: 0.3487\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8871 - loss: 0.3086 - val_accuracy: 0.8761 - val_loss: 0.3375\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8877 - loss: 0.3011 - val_accuracy: 0.8771 - val_loss: 0.3386\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8892 - loss: 0.3010 - val_accuracy: 0.8781 - val_loss: 0.3343\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8918 - loss: 0.2942 - val_accuracy: 0.8784 - val_loss: 0.3367\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8914 - loss: 0.2981 - val_accuracy: 0.8759 - val_loss: 0.3460\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8924 - loss: 0.2961 - val_accuracy: 0.8782 - val_loss: 0.3337\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8942 - loss: 0.2903 - val_accuracy: 0.8761 - val_loss: 0.3345\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8946 - loss: 0.2883 - val_accuracy: 0.8749 - val_loss: 0.3380\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8957 - loss: 0.2837 - val_accuracy: 0.8789 - val_loss: 0.3334\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8959 - loss: 0.2831 - val_accuracy: 0.8791 - val_loss: 0.3318\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8954 - loss: 0.2842 - val_accuracy: 0.8782 - val_loss: 0.3357\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8972 - loss: 0.2788 - val_accuracy: 0.8797 - val_loss: 0.3256\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8958 - loss: 0.2838 - val_accuracy: 0.8827 - val_loss: 0.3220\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8990 - loss: 0.2741 - val_accuracy: 0.8755 - val_loss: 0.3367\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8969 - loss: 0.2810 - val_accuracy: 0.8815 - val_loss: 0.3209\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8981 - loss: 0.2735 - val_accuracy: 0.8763 - val_loss: 0.3323\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8977 - loss: 0.2762 - val_accuracy: 0.8823 - val_loss: 0.3178\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9020 - loss: 0.2702 - val_accuracy: 0.8804 - val_loss: 0.3242\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9005 - loss: 0.2703 - val_accuracy: 0.8792 - val_loss: 0.3188\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9009 - loss: 0.2690 - val_accuracy: 0.8842 - val_loss: 0.3177\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9000 - loss: 0.2725 - val_accuracy: 0.8844 - val_loss: 0.3175\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9041 - loss: 0.2608 - val_accuracy: 0.8821 - val_loss: 0.3214\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9042 - loss: 0.2627 - val_accuracy: 0.8875 - val_loss: 0.3109\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9054 - loss: 0.2606 - val_accuracy: 0.8851 - val_loss: 0.3140\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9037 - loss: 0.2638 - val_accuracy: 0.8881 - val_loss: 0.3089\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9064 - loss: 0.2561 - val_accuracy: 0.8834 - val_loss: 0.3190\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9041 - loss: 0.2588 - val_accuracy: 0.8874 - val_loss: 0.3072\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9066 - loss: 0.2567 - val_accuracy: 0.8905 - val_loss: 0.3049\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9085 - loss: 0.2538 - val_accuracy: 0.8850 - val_loss: 0.3184\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9046 - loss: 0.2584 - val_accuracy: 0.8873 - val_loss: 0.3059\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9083 - loss: 0.2511 - val_accuracy: 0.8886 - val_loss: 0.3060\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9074 - loss: 0.2500 - val_accuracy: 0.8916 - val_loss: 0.3026\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9072 - loss: 0.2517 - val_accuracy: 0.8907 - val_loss: 0.3007\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9095 - loss: 0.2486 - val_accuracy: 0.8839 - val_loss: 0.3181\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9076 - loss: 0.2480 - val_accuracy: 0.8925 - val_loss: 0.3022\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9115 - loss: 0.2432 - val_accuracy: 0.8862 - val_loss: 0.3140\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9114 - loss: 0.2446 - val_accuracy: 0.8873 - val_loss: 0.3148\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9117 - loss: 0.2442 - val_accuracy: 0.8906 - val_loss: 0.2999\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9110 - loss: 0.2401 - val_accuracy: 0.8928 - val_loss: 0.2975\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9107 - loss: 0.2426 - val_accuracy: 0.8861 - val_loss: 0.3104\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9114 - loss: 0.2422 - val_accuracy: 0.8930 - val_loss: 0.2981\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9137 - loss: 0.2373 - val_accuracy: 0.8931 - val_loss: 0.2983\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9125 - loss: 0.2378 - val_accuracy: 0.8889 - val_loss: 0.3030\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9131 - loss: 0.2382 - val_accuracy: 0.8927 - val_loss: 0.2974\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9146 - loss: 0.2351 - val_accuracy: 0.8896 - val_loss: 0.3049\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9135 - loss: 0.2323 - val_accuracy: 0.8867 - val_loss: 0.3121\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9106 - loss: 0.2387 - val_accuracy: 0.8927 - val_loss: 0.3044\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9135 - loss: 0.2366 - val_accuracy: 0.8922 - val_loss: 0.3046\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9111 - loss: 0.2364 - val_accuracy: 0.8935 - val_loss: 0.3018\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9134 - loss: 0.2331 - val_accuracy: 0.8927 - val_loss: 0.2996\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9152 - loss: 0.2297 - val_accuracy: 0.8913 - val_loss: 0.3018\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9145 - loss: 0.2296 - val_accuracy: 0.8935 - val_loss: 0.2987\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9152 - loss: 0.2290 - val_accuracy: 0.8924 - val_loss: 0.3016\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9160 - loss: 0.2289 - val_accuracy: 0.8935 - val_loss: 0.2935\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9159 - loss: 0.2306 - val_accuracy: 0.8929 - val_loss: 0.3009\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9155 - loss: 0.2278 - val_accuracy: 0.8936 - val_loss: 0.2966\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9187 - loss: 0.2248 - val_accuracy: 0.8928 - val_loss: 0.2969\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9180 - loss: 0.2256 - val_accuracy: 0.8966 - val_loss: 0.2911\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9212 - loss: 0.2175 - val_accuracy: 0.8960 - val_loss: 0.2929\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9194 - loss: 0.2176 - val_accuracy: 0.8963 - val_loss: 0.2932\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9202 - loss: 0.2161 - val_accuracy: 0.8973 - val_loss: 0.2912\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9198 - loss: 0.2214 - val_accuracy: 0.8941 - val_loss: 0.2940\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9199 - loss: 0.2177 - val_accuracy: 0.8950 - val_loss: 0.2934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fc044286d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compile and fit your model\n",
    "import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = lenet5()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define now our callbacks\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "# Finally fit the model\n",
    "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf-SqjjOyO8q"
   },
   "source": [
    "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2FTj7TSyO8q"
   },
   "source": [
    "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPjJoMQZyO8q",
    "outputId": "208f6295-df11-4146-8eeb-e81f1c4322d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "accuracy on train with NN: 0.9222333333333333\n",
      "accuracy on test with NN: 0.895\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vulsgHiyO8q"
   },
   "source": [
    "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
    "\n",
    "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
    "* `horizontal_flip=True`\n",
    "\n",
    "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
    "\n",
    "Begin by creating an object `ImageDataGenerator` with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:58:37.442182Z",
     "start_time": "2020-08-19T11:58:37.438397Z"
    },
    "id": "pas-fMSIyO8q"
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate an ImageDataGenerator object\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7nCnu9syO8r"
   },
   "source": [
    "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zt6wXa3IyO8r",
    "outputId": "aa6078bb-d14e-4c98-97d0-49cdec4785f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 1/58\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 584ms/step - accuracy: 0.8086 - loss: 1.6801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\61406\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8239 - loss: 0.6877 - val_accuracy: 0.8801 - val_loss: 0.3342\n",
      "Epoch 2/100\n",
      "\u001b[1m 1/58\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8711 - loss: 0.3564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\61406\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8711 - loss: 0.3564 - val_accuracy: 0.8841 - val_loss: 0.3288\n",
      "Epoch 3/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.8861 - loss: 0.3116 - val_accuracy: 0.8852 - val_loss: 0.3165\n",
      "Epoch 4/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.2774 - val_accuracy: 0.8874 - val_loss: 0.3078\n",
      "Epoch 5/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8969 - loss: 0.2848 - val_accuracy: 0.8884 - val_loss: 0.3083\n",
      "Epoch 6/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8838 - loss: 0.3065 - val_accuracy: 0.8907 - val_loss: 0.3028\n",
      "Epoch 7/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8994 - loss: 0.2765 - val_accuracy: 0.8921 - val_loss: 0.2955\n",
      "Epoch 8/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9043 - loss: 0.2890 - val_accuracy: 0.8935 - val_loss: 0.2956\n",
      "Epoch 9/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9033 - loss: 0.2672 - val_accuracy: 0.8904 - val_loss: 0.2988\n",
      "Epoch 10/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.2384 - val_accuracy: 0.8904 - val_loss: 0.2967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fc048f8610>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: train your model\n",
    "batch_size = 1024\n",
    "#below did not work in my version \n",
    "# model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
    "#                     validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
    "#                     steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)\n",
    "\n",
    "model.fit(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
    "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
    "                    steps_per_epoch=int(len(X_train_norm) / batch_size), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuzFke8pyO8r"
   },
   "source": [
    "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsTm86tuyO8r",
    "outputId": "36b5c6a1-63b6-4a92-82ea-961422411014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "accuracy on train with NN: 0.9147333333333333\n",
      "accuracy on test with NN: 0.8904\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size=1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOzkdGf7yO8s"
   },
   "source": [
    "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "01-LeNet5-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
