{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayaw00d/3803ict-workshops/blob/main/02-Recommendation-Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK8fe0c-jxIY"
      },
      "source": [
        "# Recommendation - Model üçø"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOh55L5SjxIZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOCWCiZmjxIZ"
      },
      "source": [
        "<img src=\"https://visithrastnik.si/uploads/tic/public/generic_list_item/6-kulturna_prireditev_v_avli_kulturnega_centra_zagorje_ob_savi.jpg\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjU7o0fojxIZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILYMaaQjxIZ"
      },
      "source": [
        "Now, time for the exciting part! We will train a Machine Learning model based on our previous **ratings** sparse matrix, so that it creates a recommendation engine automatically!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow8zYBoMjxIZ"
      },
      "source": [
        "First, load again the dataframe `movies` and `ratings`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JeFMuuSRjxIZ"
      },
      "outputs": [],
      "source": [
        "### TODO: load the movies and ratings datasetsimport pandas as pd\n",
        "import pandas as pd\n",
        "### TODO: Load the movies and ratings datasets\n",
        "movies = pd.read_csv(\"./ml-latest-small/movies.csv\")\n",
        "ratings = pd.read_csv(\"./ml-latest-small/ratings.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hpYUYkojxIa"
      },
      "source": [
        "**Q1**. Start by loading all the pickle you saved during last challenge: `ratings_matrix`, `idx_to_mid`, `mid_to_idx`, `uid_to_idx`, `idx_to_uid`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Be-KZTa9jxIa"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "root = \"./data/netflix/\"\n",
        "ratings_matrix = pickle.load(open(root + \"ratings_matrix.pkl\", \"rb\"))\n",
        "idx_to_mid = pickle.load(open(root + \"idx_to_mid.pkl\", \"rb\"))\n",
        "mid_to_idx = pickle.load(open(root + \"mid_to_idx.pkl\", \"rb\"))\n",
        "uid_to_idx = pickle.load(open(root + \"uid_to_idx.pkl\", \"rb\"))\n",
        "idx_to_uid = pickle.load(open(root + \"idx_to_uid.pkl\", \"rb\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHJdfIWHjxIa"
      },
      "source": [
        "**Q2**. Because the dataset is slightly different from what we have been used to (X as features, y as target), the usual `train_test_split` method from scikit-learn does not apply.\n",
        "\n",
        "Hopefully, `lightfm` comes with a `random_train_test_split` located into `cross_validation` dedicated to this usecase üôÇ\n",
        "\n",
        "Split the data randomly into a `train` matrix and a `test` matrix with 20% of interactions into the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "337ynC3sjxIa",
        "outputId": "1b772a3a-7b57-4b18-f834-8eaed444c37c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.10/dist-packages (1.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.5.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((610, 9724), (610, 9724))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "!pip install lightfm\n",
        "import numpy as np\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "\n",
        "train, test = random_train_test_split(ratings_matrix, test_percentage=0.2, random_state=np.random.RandomState(0))\n",
        "\n",
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO-EJHBZjxIa"
      },
      "source": [
        "**Q3**. Train a LightFM model for 10 epochs. You can use the parameter `loss=\"warp\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH5VoHeRjxIb",
        "outputId": "427bc42f-e712-4a98-8b3d-1f5585cb4be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:04<00:00,  2.10it/s]\n"
          ]
        }
      ],
      "source": [
        "from lightfm import LightFM\n",
        "\n",
        "light_model = LightFM(no_components=100, loss='warp', random_state=0)\n",
        "try:\n",
        "    light_model.fit(train, epochs=10, verbose=True)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TQh6RZwjxIb"
      },
      "source": [
        "**Q4**. Evaluate your model on your test set. You can use the `precision_at_k` metric implemented in the LightFM library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEDXAhAojxIb",
        "outputId": "def3227c-eaee-41e1-ac83-dfc1ef0f9171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision at K = 5\n",
            "0.2680921\n"
          ]
        }
      ],
      "source": [
        "from lightfm.evaluation import precision_at_k\n",
        "\n",
        "k=5\n",
        "pre_k = precision_at_k(light_model, test, train, k=k).mean()\n",
        "\n",
        "print(\"Precision at K =\", k)\n",
        "print(pre_k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocFQ4UogjxIb"
      },
      "source": [
        "**Q5**. What does the attribute `item_embeddings` of `model` contains?  This will be the heart of your recommendation engine! üíü So make sure you understand fully what it contains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu8Lr9RgjxIb",
        "outputId": "bc0c6dfd-f40c-4188-9f3a-7ba668ec9585"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9724, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "light_model.item_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"item_embeddings contains all movies into a vector of 100 dimensions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVc4IACjk7-x",
        "outputId": "49f916c9-6d2d-472b-f70e-bfc8a137592f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item_embeddings contains all movies into a vector of 100 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_model.item_embeddings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG9-Fj3Bk9HV",
        "outputId": "4db7c7f9-99b8-438a-b599-d89a50ae250c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.3142591 , -0.2041731 ,  0.08945829, -0.08405492,  0.34734696,\n",
              "       -0.05399103,  0.11160227, -0.20095833, -0.11371228, -0.39413986,\n",
              "        0.362561  ,  0.05316165, -0.4583187 , -0.34357777, -0.18797755,\n",
              "       -0.00553624,  0.28137276,  0.43153363,  0.15660733, -0.40245408,\n",
              "        0.40595597,  0.01247011, -0.27369824, -0.14441921,  0.20417038,\n",
              "        0.02513273,  0.2091002 , -0.15891656,  0.2149729 ,  0.14988837,\n",
              "       -0.21464817,  0.23834325, -0.2145693 ,  0.24521717, -0.37559548,\n",
              "        0.22957776, -0.12345305,  0.40108737, -0.36697736,  0.22383201,\n",
              "        0.223479  ,  0.34414145,  0.2924009 , -0.08213998, -0.16994385,\n",
              "        0.14942707,  0.3083662 , -0.29354784,  0.2813535 ,  0.19445191,\n",
              "       -0.09893961,  0.18049172,  0.2639099 , -0.2928732 ,  0.22133411,\n",
              "        0.3848023 , -0.3763623 , -0.39090097,  0.1398391 , -0.19342977,\n",
              "        0.2217506 , -0.25360197, -0.04459268, -0.24561936, -0.24732517,\n",
              "       -0.2852928 , -0.3145209 ,  0.23152035, -0.08398732,  0.2357348 ,\n",
              "        0.43923882, -0.22179724, -0.26850736,  0.2287694 ,  0.31319067,\n",
              "       -0.45152718,  0.29074073,  0.14896719, -0.17075899,  0.36414906,\n",
              "        0.31535566, -0.36333334, -0.30940136, -0.18098393,  0.25576434,\n",
              "        0.13181838, -0.24876045,  0.06040273,  0.21618365,  0.00862575,\n",
              "        0.4239635 , -0.19704804, -0.24612795,  0.00307926,  0.03299215,\n",
              "        0.26428193,  0.21571033,  0.16809924,  0.3242619 ,  0.49499956],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVRUJt9jjxIb"
      },
      "source": [
        "**Q6**. We just trained a model that factorized our ratings matrix into a U matrix of shape (n_users, no_components) : `model.user_embeddings` ; and V matrix of shape (n_movies, no_components) : `model.item_embeddings`).\n",
        "\n",
        "Now we want to compute **similarity between each pair of movies**.\n",
        "\n",
        "> üî¶ **Hint**: For the similarity distance we can either use `cosine_similarity` function or `pearson_similarity`:\n",
        "> - **Cosine similarity** between two vectors, or matrices X and Y is given by:\n",
        "> ``` python\n",
        "> from sklearn.metrics.pairwise import cosine_similarity\n",
        "> cosine_similarity(X, Y)\n",
        "> ```\n",
        "> - **Pearson similarity** between two vectors, or matrices X and Y is given by:\n",
        "> ``` python\n",
        "> import numpy as np\n",
        "> np.corrcoef(X, Y)\n",
        "> ```\n",
        "\n",
        "Compute the `similarity_scores` of size (n_movies, n_movies), containing for each element (i, j) the similarity between movie of index i and movie of index j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFJ0WuKRjxIb",
        "outputId": "0c64dcdd-c663-4b11-b9d9-1471464455f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9999999 ,  0.35686016,  0.5590585 , ..., -0.25982952,\n",
              "        -0.3204423 , -0.3208219 ],\n",
              "       [ 0.35686016,  1.        ,  0.4236118 , ..., -0.29630297,\n",
              "        -0.30853668, -0.2569683 ],\n",
              "       [ 0.5590585 ,  0.4236118 ,  1.        , ..., -0.27644306,\n",
              "        -0.18271977, -0.15962668],\n",
              "       ...,\n",
              "       [-0.25982952, -0.29630297, -0.27644306, ...,  1.        ,\n",
              "         0.7492958 ,  0.6513411 ],\n",
              "       [-0.3204423 , -0.30853668, -0.18271977, ...,  0.7492958 ,\n",
              "         0.9999997 ,  0.8015574 ],\n",
              "       [-0.3208219 , -0.2569683 , -0.15962668, ...,  0.6513411 ,\n",
              "         0.8015574 ,  1.0000001 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similar_score = cosine_similarity(light_model.item_embeddings) #using method 1 cosine\n",
        "similar_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_score_np = np.corrcoef(light_model.item_embeddings) #using method 2 corr coef\n",
        "similar_score_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4RjO9tQlBiB",
        "outputId": "1e18a308-abae-435b-8838-02685bc381c3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.35021119,  0.55637834, ..., -0.26238036,\n",
              "        -0.33058201, -0.32973479],\n",
              "       [ 0.35021119,  1.        ,  0.4183909 , ..., -0.30211544,\n",
              "        -0.32621165, -0.27207356],\n",
              "       [ 0.55637834,  0.4183909 ,  1.        , ..., -0.27883183,\n",
              "        -0.19122061, -0.16694876],\n",
              "       ...,\n",
              "       [-0.26238036, -0.30211544, -0.27883183, ...,  1.        ,\n",
              "         0.75087505,  0.65203931],\n",
              "       [-0.33058201, -0.32621165, -0.19122061, ...,  0.75087505,\n",
              "         1.        ,  0.80003545],\n",
              "       [-0.32973479, -0.27207356, -0.16694876, ...,  0.65203931,\n",
              "         0.80003545,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4IgN9ZBalAD4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3J58lxTjxIb"
      },
      "source": [
        "**Q7**. For movie of idx 20, what are the idx of the 10 most similar movies?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ihIHZjjxIb",
        "outputId": "6819ed3f-6203-4035-9c72-c5c57ba4de65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[314    Forrest Gump (1994)\n",
              " Name: title, dtype: object,\n",
              " 277    Shawshank Redemption, The (1994)\n",
              " Name: title, dtype: object,\n",
              " 257    Pulp Fiction (1994)\n",
              " Name: title, dtype: object,\n",
              " 224    Star Wars: Episode IV - A New Hope (1977)\n",
              " Name: title, dtype: object,\n",
              " 0    Toy Story (1995)\n",
              " Name: title, dtype: object,\n",
              " 461    Schindler's List (1993)\n",
              " Name: title, dtype: object,\n",
              " 418    Jurassic Park (1993)\n",
              " Name: title, dtype: object,\n",
              " 43    Seven (a.k.a. Se7en) (1995)\n",
              " Name: title, dtype: object,\n",
              " 325    Mask, The (1994)\n",
              " Name: title, dtype: object,\n",
              " 510    Silence of the Lambs, The (1991)\n",
              " Name: title, dtype: object]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "idx = 20 #id of 20\n",
        "similar_idx = similar_score[idx]\n",
        "ranked_idx = np.argsort(-similar_idx)\n",
        "ranked_mid = [idx_to_mid[x] for x in ranked_idx]\n",
        "\n",
        "[movies[movies.movieId == mid][\"title\"] for mid in ranked_mid[:10]] #top 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uBFogdojxIb"
      },
      "source": [
        "**Q8**. Let's now test our engine! Suppose we have an user that likes **Toy Story** üß∏ (movie_id = 1). Which movies would you recommend to that user? In other words, which movies are the most similar to the movie Toy Story\n",
        "\n",
        "> ‚ö†Ô∏è **Warning**: Remember that your `similarity_scores` works with `idx` and you have the `movie_id` associated to your movie.\n",
        "\n",
        "Retrieve the **top 5 recommendations**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NMPgz0rjxIb",
        "outputId": "75583b31-2d8b-43f0-cfa9-a99dbb7ac285"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0    Toy Story (1995)\n",
              " Name: title, dtype: object,\n",
              " 314    Forrest Gump (1994)\n",
              " Name: title, dtype: object,\n",
              " 277    Shawshank Redemption, The (1994)\n",
              " Name: title, dtype: object,\n",
              " 224    Star Wars: Episode IV - A New Hope (1977)\n",
              " Name: title, dtype: object,\n",
              " 257    Pulp Fiction (1994)\n",
              " Name: title, dtype: object]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "idx = mid_to_idx[1]\n",
        "similar_idx = similar_score[idx]\n",
        "ranked_idx = np.argsort(-similar_idx)\n",
        "ranked_mid = [idx_to_mid[x] for x in ranked_idx]\n",
        "\n",
        "[movies[movies.movieId == mid][\"title\"] for mid in ranked_mid[:5]] #get top 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqxNiqrUjxIc"
      },
      "source": [
        "As the next step is to **deploy your model**, you need now to:\n",
        "\n",
        "**Q9**. Save your `similarity_scores` into pickle format. Save also `movies` DataFrame into pickle format. Save them at the `data/netflix` directory at the root of the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_zBKp9V-jxIc"
      },
      "outputs": [],
      "source": [
        "with open(root + '/similarity_scores.pkl', 'wb') as f:\n",
        "    pickle.dump(similar_score, f)\n",
        "\n",
        "with open(root + '/movies.pkl', 'wb') as f:\n",
        "    pickle.dump(movies, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYmU6EAhjxIc"
      },
      "source": [
        "**Q10**. Encapsulate the previous code into functions, especially you will need:\n",
        "- `get_sim_scores(mid)` function that returns the vector of the similarity scores `sims` between a movie `mid` and all the other movies\n",
        "- `get_ranked_recos(sims)` that returns for a vector of similarity scores `sims` the list of all ranked recommendations (n_movies) (from most recommended to least recommended) - in the format list of (mid, score, name) tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sdgqb7HPjxIc"
      },
      "outputs": [],
      "source": [
        "def get_movie_name(mid, movies):\n",
        "    try:\n",
        "        name = movies.loc[movies.movieId == mid].title.values[0]\n",
        "    except:\n",
        "        name = 'unknown'\n",
        "    return name\n",
        "\n",
        "def get_sim_scores(mid):\n",
        "    idx = mid_to_idx[mid]\n",
        "    sim_score = similar_score[idx]\n",
        "    return sim_score\n",
        "\n",
        "def get_ranked_recos(sim_scores):\n",
        "    recos = []\n",
        "    for idx in np.argsort(-sim_scores):\n",
        "        mid = idx_to_mid[idx]\n",
        "        name = get_movie_name(mid, movies)\n",
        "        score = sim_scores[idx]\n",
        "        recos.append((mid, score, name))\n",
        "\n",
        "    return recos\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZh9KCt_jxIc",
        "outputId": "e573634c-da12-4a3f-ef70-a5bd890d3548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 1.0, 'Grumpier Old Men (1995)'),\n",
              " (65, 0.69877565, 'Bio-Dome (1996)'),\n",
              " (432, 0.6745255, \"City Slickers II: The Legend of Curly's Gold (1994)\"),\n",
              " (234, 0.65149, 'Exit to Eden (1994)'),\n",
              " (415, 0.6485228, 'Another Stakeout (1993)'),\n",
              " (553, 0.6474647, 'Tombstone (1993)'),\n",
              " (880, 0.6424499, 'Island of Dr. Moreau, The (1996)'),\n",
              " (1405, 0.62317276, 'Beavis and Butt-Head Do America (1996)'),\n",
              " (1049, 0.621908, 'Ghost and the Darkness, The (1996)'),\n",
              " (466, 0.6159928, 'Hot Shots! Part Deux (1993)')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "sims = get_sim_scores(3)\n",
        "recos = get_ranked_recos(sims)[:10]\n",
        "\n",
        "recos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyJPRZ1njxIc"
      },
      "source": [
        "If you have extra time, feel free now to improve your recommendation engine!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}