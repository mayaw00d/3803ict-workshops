{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation - Data Preparation üé¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1200/0*ePGWILY6GyplT-nn\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few challenges, you will build a powerful **movie recommender**.\n",
    "\n",
    "We will use the open-source library [LightFM](https://github.com/lyst/lightfm) which provides easy python implementation of **hybrid** recommendation engines.\n",
    "\n",
    "In this first part, we will prepare the data in order to train efficiently of the model.\n",
    "\n",
    "We let you load the data `movies` and `ratings` downloaded from the **small** [movielens dataset](https://grouplens.org/datasets/movielens/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Load the movies and ratings datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. What are the different types of recommendation models? Explain briefly with your own words the differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1bis**. What data is expected by the LightFM `fit` method? Especially, how does the train data should be organized, and what should be the type of the train dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Explore `movies` and `ratings`, what do those datasets contain? How are they organized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratings.shape)\n",
    "print(ratings.head())\n",
    "\n",
    "len(ratings['userId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###¬†Q3 & Q4 are optional\n",
    "> you can come back to it if you have time after having finished the whole project of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a few utils functions for you in `utils.py` script. Especially:\n",
    "- `threshold_interactions_df`:\n",
    "> Limit interactions df to minimum row and column interactions\n",
    "\n",
    "**Q3**. Open `src/utils.py` file, and have a look at the documentation of this function to understand its goal and how it works.\n",
    "\n",
    "Have a look the code to understand fully how it works. You should be familiar with everything.\n",
    "\n",
    "What does represent the variable `sparsity`? What is the range of values in which sparsity can be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. Create a new DataFrame `ratings_thresh`, that filters `ratings` with only:\n",
    "- users that rated strictly more than 4 movies\n",
    "- movies that have been rated at least 10 times\n",
    "\n",
    "How many users/movies remain in this new dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import threshold_interactions_df\n",
    "# threshold data to include\n",
    "# users that rated >= 5 moveis\n",
    "# movies that have been rated by >= 10 users\n",
    "ratings_thresh = threshold_interactions_df(ratings, 'userId', 'movieId', )\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_thresh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. In order to fit a [LightFM](https://lyst.github.io/lightfm/docs/home.html) model, we need to transform our Dataframe to a sparse matrix (cf. below). This is not straightforward so we included the function `df_to_matrix` in `utils.py`.\n",
    "\n",
    "> üî¶ **Hint**:  Sparse matrices are just **big matrices with a lot of zeros or empty values**.\n",
    "> \n",
    "> Existing tools (Pandas DataFrame, Numpy arrays for example) are not suitable for manipulating this kind of data. So we will use [Scipy sparse matrices](https://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html).\n",
    ">\n",
    "> It exists many different \"types\" of sparse matrices (CSC, CSR, COO, DIA, etc.). You don't need to know them. Just know that it corresponds to different formats with different methods of manipulation, slicing, indexing, etc.\n",
    "\n",
    "> üî¶ **Hint 2**:  By going from a DataFrame to a sparse matrix, you will lose the information of the ids (userId and movieId), you will only deal with indices (row number and column number). Therefore, the `df_to_matrix` function also returns dictionaries mapping indexes to ids (ex: uid_to_idx mapping userId to index of the matrix) \n",
    "\n",
    "\n",
    "Have a look at the util function documentation, and use it to create 5 new variables:\n",
    "- a final sparse matrix `ratings_matrix` (this will be the data used to train the model)\n",
    "- the following utils mappers:\n",
    "    - `uid_to_idx`\n",
    "    - `idx_to_uid`\n",
    "    - `mid_to_idx`\n",
    "    - `idx_to_mid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**.\n",
    "- On the one side, find what movies did the userId 4 rate?\n",
    "\n",
    "- On the other side, what is the value of `ratings_matrix` for:\n",
    "    - userId = 4 and movieId=1\n",
    "    - userId = 4 and movieId=2\n",
    "    - userId = 4 and movieId=21\n",
    "    - userId = 4 and movieId=32\n",
    "    - userId = 4 and movieId=126\n",
    "\n",
    "Conclude on the values signification in `ratings_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. Now that you have a `ratings_matrix` in the correct format, let's save it in pickle format:\n",
    "- Create a variable `dst_dir` corresponding to the path of the folder `data/netflix` located at the root of the repository\n",
    "- **Verify that this is the correct path**\n",
    "- Save the ratings_matrix in pickle (as `ratings_matrix.pkl`) in this corresponding directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. Save also all mappings objects into pickle (`idx_to_mid`, `mid_to_idx`, `uid_to_idx`, `idx_to_uid`) as it will be useful for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to next challenge now! üçø"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
